{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9988"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the json FIle contain tweets and there labes \n",
    "#For train and test\n",
    "from pyspark.sql import SparkSession\n",
    "jobDir = \"tweets111.json\"\n",
    "tweets = spark.read.json([jobDir])\n",
    "tweets.count() #number of tweets in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select the object in json file\n",
    "tweets = tweets.select(\"text\", \\\n",
    "                     \"Category\" )\n",
    "\n",
    "tweets.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer,CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "#convert a collection of text documents to vectors of token counts. \n",
    "countVectors = CountVectorizer(inputCol=\"words\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "|text                                             |Category|words                                                      |label|features                                                                                      |\n",
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "|ÙˆØ§Ù„Ù„ Ø¹Ø¬Ø¨ Ø¹Ø´Ø§Ù† ÙƒØªØ§Ø¨ Ø§Ù†Ø¬Ù„ÙŠØ² ØµØ¹Ø¨ ÙƒÙ„Ù…                |POS     |[ÙˆØ§Ù„Ù„, Ø¹Ø¬Ø¨, Ø¹Ø´Ø§Ù†, ÙƒØªØ§Ø¨, Ø§Ù†Ø¬Ù„ÙŠØ², ØµØ¹Ø¨, ÙƒÙ„Ù…]                  |1.0  |(19722,[47,92,176,419,588,1350,6837],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                           |\n",
      "|Ø§Ù†Ù‡ Ø±Ù†Ø§Ù…Ø¬ Ø±Ø§ÙŠØ¹ ÙŠØªØ±Ø¬Ù… ÙƒÙ„Ù… Ù‚Ø·Ø¹ Ø¨Ø§Ù‚Øµ Ø³Ø±Ø¹            |POS     |[Ø§Ù†Ù‡, Ø±Ù†Ø§Ù…Ø¬, Ø±Ø§ÙŠØ¹, ÙŠØªØ±Ø¬Ù…, ÙƒÙ„Ù…, Ù‚Ø·Ø¹, Ø¨Ø§Ù‚Øµ, Ø³Ø±Ø¹]             |1.0  |(19722,[22,176,291,308,1180,2074,2930,12880],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])               |\n",
      "|Ø±Ù†Ø§Ù…Ø¬ Ø¬Ù…ÙŠÙ„ Ø¬Ø¯Ø§ ÙŠØªØ±Ø¬Ù… ÙƒÙ„Ù… Ø¬Ù…Ù„ ÙØ¹Ù„ Ø±ÙˆØ¹             |POS     |[Ø±Ù†Ø§Ù…Ø¬, Ø¬Ù…ÙŠÙ„, Ø¬Ø¯Ø§, ÙŠØªØ±Ø¬Ù…, ÙƒÙ„Ù…, Ø¬Ù…Ù„, ÙØ¹Ù„, Ø±ÙˆØ¹]              |1.0  |(19722,[99,116,135,176,308,1497,2930,3764],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                 |\n",
      "|Ù‚Ù…Ù‡ Ø±ÙˆØ¹Ù‡ Ø§Ù„Ù Ø´ÙƒØ± ØªÙ‚Ø¯ÙŠØ± Ù…Ø¬Ù‡ÙˆØ¯ Ù†Ø§ÙØ¹ Ø¬Ø¯Ø§ ØªØ­ÙŠ Ø§Ø­ØªØ±Ø§Ù… |POS     |[Ù‚Ù…Ù‡, Ø±ÙˆØ¹Ù‡, Ø§Ù„Ù, Ø´ÙƒØ±, ØªÙ‚Ø¯ÙŠØ±, Ù…Ø¬Ù‡ÙˆØ¯, Ù†Ø§ÙØ¹, Ø¬Ø¯Ø§, ØªØ­ÙŠ, Ø§Ø­ØªØ±Ø§Ù…]|1.0  |(19722,[97,99,108,485,768,1231,1763,2351,4526,5724],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|Ø¬Ù…ÙŠÙ„ Ø§Ø´Ø®Ø§Øµ Ø§ÙŠØ¬Ø¯ Ø§Ù†Ø¬Ù„Ø²ÙŠÙ‡                          |POS     |[Ø¬Ù…ÙŠÙ„, Ø§Ø´Ø®Ø§Øµ, Ø§ÙŠØ¬Ø¯, Ø§Ù†Ø¬Ù„Ø²ÙŠÙ‡]                               |1.0  |(19722,[116,707,17003,18478],[1.0,1.0,1.0,1.0])                                               |\n",
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import  StringIndexer\n",
    "#StringIndexer encodes a string column of labels to a column of label indices.\n",
    "label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "#pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, label_stringIdx, countVectors])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "dataset.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 7957\n",
      "Test Dataset Count: 2031\n"
     ]
    }
   ],
   "source": [
    "#Partition Training & Test sets\n",
    "#80% train ,20% test\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------+-----+----------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |probability                                                   |label|prediction|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------+-----+----------+\n",
      "|ÙˆØ§Ù†Ø§ Ø´Ø§Ù‡Ø¯ Ù…Ù†Ø¸Ø± ÙˆÙ‚Ù„ Ù„Ù†ÙØ³ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ÙŠâœ‹ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ÙŠâœ‹ ÙˆØ§Ù†Ø§ Ø´Ø§Ù‡Ø¯ Ù…Ù†Ø¸Ø± ÙˆÙ‚Ù„ Ù„Ù†ÙØ³ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨ Ø¸Ø± ÙˆÙ‚Ù„ Ù„Ù†ÙØ³ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠ |[0.9999210491771423,3.95787130806775E-5,3.9372109776858436E-5]|0.0  |0.0       |\n",
      "|Ø§Ø­ØªÙ„Ø§Ù„ ÙŠØ­ÙƒÙ… Ø¨Ø§Ù„Ø³Ø¬ Ù…ÙˆØ¨Ø¯ ØºØ±Ø§Ù… Ù‚ÙŠÙ… Ø§Ù„Ù Ø´ÙŠÙ‚Ù„ Ø§Ø®Ùˆ Ù†ØµØ± Ø§ÙƒØ±Ù… Ø¨Ø¯Ùˆ ØªÙ†ÙÙŠØ° Ø³Ù„Ø³Ù„ Ø¹Ù…Ù„ÙŠØ§â€¦ Ø§Ø­ØªÙ„Ø§Ù„ ÙŠØ­ÙƒÙ… Ø¨Ø§Ù„Ø³Ø¬ Ù…ÙˆØ¨Ø¯ ØºØ±Ø§Ù…                                                                                                                                                                                                                                                                                                                                                              |[0.9837874814356192,0.006807297992765309,0.009405220571615606]|0.0  |0.0       |\n",
      "|Ø§ÙŠÙ‡ ÙˆØ§Ù„Ù„ ğŸ˜” ğŸ’” Ø±Ø¨ ÙŠØºÙØ± ÙŠØ±Ø­Ù… ÙˆÙŠØ³ Ø³ÙŠØ­ Ø¬Ù†Ø§ ÙŠØºÙØ± Ù„Ø§Ø¨ ÙŠØ¬Ù…Ø¹ Ø¬Ù†Ø§ Ù†Ø¹ÙŠÙ… ÙŠØ§Ø±Ø¨ Ø¹Ø§Ù„Ù…                                                                                                                                                                                                                                                                                                                                                                                             |[0.9764074409260085,0.012596349190770144,0.010996209883221413]|0.0  |0.0       |\n",
      "|Ø¹Ø§Ø¬Ù„ Ø§Ø³ØªÙ‚Ø§Ù„ Ø±ÙŠÙŠØ³ Ø­ÙƒÙˆÙ…Ù‡ Ù„Ø¨Ù†Ø§Ù†ÙŠÙ‡ Ø³Ø¹Ø¯ Ø­Ø±ÙŠØ± ØªÙ†ÙØ³ ØµØ¹Ø¯Ø§Ø¡ Ø¯ÙˆØ§Ø¹Ø´ ØªÙ‚Ø¯Ù… Ø´ÙƒØ± Ù„Ù…Ù…Ù„ Ø§Ù„ Ø³Ø¹ÙˆØ¯ Ù„Ø§Ù† Ø§Ø²â€¦ ØªÙ†ÙØ³ ØµØ¹Ø¯Ø§Ø¡ Ø¯ÙˆØ§Ø¹Ø´                                                                                                                                                                                                                                                                                                                                                              |[0.9719564169446698,0.01574105429442088,0.01230252876090918]  |0.0  |0.0       |\n",
      "|Ø§Ù…Ø±ÙŠÙƒ Ø¯Ù„ÙˆÙ‚Øª Ù…Ø­Ø· Ù†ÙˆÙˆÙŠÙ‡ Ø´ØºØ§Ù„ Ø±Ø§Ù…Ø¬ ÙØ¶Ø§Ø¡ Ø´ØºØ§Ù„ Ø§Ø¨Ø­Ø§Ø« Ø¹Ù„Ù…ÙŠÙ‡ Ø§Ø³ØªØ¯ÙŠÙˆÙ‡Ø§ Ù…ØµØ§Ù†Ø¹ Ø§Ø­Ø²Ø§Ø¨ Ø­Ø±ÙƒØ§ Ø±ÙØ¶Ø§Ù†Øª Ø¨Ù‚ÙŠ Ø´ØºØ§Ù„ Ø§ÙŠÙ‡                                                                                                                                                                                                                                                                                                                                                                  |[0.9687907628734362,0.013005416123844116,0.018203821002719674]|0.0  |0.0       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression using Count Vector Features\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)# model will make predictions and score on the test set\n",
    "\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.7026545276911003\n"
     ]
    }
   ],
   "source": [
    "# Show the accuracy \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"f1\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|             1157|\n",
      "|       1.0|              600|\n",
      "|       2.0|              274|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 71.147%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+--------------------------------------------------------------+-----+----------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |Category|probability                                                   |label|prediction|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+--------------------------------------------------------------+-----+----------+\n",
      "|Ø§Ù„Ù„Ù‡ ÙŠØ­Ù… ÙŠÙ†ØµØ± ÙŠÙ†ØµØ± ÙÙŠÙƒ Ø§Ù†Øª Ø§ØµÙ‡ ÙˆØ§Ù„Ù„ Ø·Ù„Ø¹ Ù…Ù†Ùƒ Ø³Ø¹Ø¯ Ø¹Ø´ØªÙ… Ø¹Ø§Ø´ Ø¨Ù†Ø§Ù† Ø¹Ø§Ø´ Ù…Ù…Ù„ÙƒÙ‡ Ø³Ø¹ÙˆØ¯ÙŠÙ‡ Ø¹Ø´ØªÙ… Ø¹Ø§Ø´ Ø¨Ù†Ø§Ù† Ø¹Ø§Ø´ Ù…Ù…Ù„ÙƒÙ‡ Ø³Ø¹ÙˆØ¯ÙŠÙ‡ Ù†Øµ ØªØºØ±ÙŠØ¯Ù‡ Ø§Ù„Ù„Ù‡ ÙŠØ­Ù… ÙŠÙ†ØµØ± ÙŠÙ†ØµØ± ÙÙŠÙƒ Ø§Ù†Øª Ø§ØµÙ‡ ÙˆØ§Ù„Ù„ Ø·Ù„Ø¹ Ù…Ù†Ùƒ Ø³Ø¹Ø¯ Ø¹Ø´ØªÙ… Ø¹Ø§Ø´ Ø¨Ù†Ø§Ù† Ø¹Ø§Ø´ Ù…Ù…Ù„ÙƒÙ‡ Ø³Ø¹ÙˆØ¯ÙŠÙ‡ Ø§Ù„Ù„Ù‡ ÙŠØ­Ù… ÙŠÙ†ØµØ± ÙŠÙ†ØµØ± ÙÙŠÙƒ Ø§Ù†Øª Ø§ØµÙ‡ ÙˆØ§Ù„Ù„ Ø·Ù„Ø¹ Ù…Ù†Ùƒ Ø³Ø¹Ø¯ Ø¹Ø´ØªÙ… Ø¹Ø§Ø´ Ø¨Ù†Ø§Ù† Ø¹Ø§Ø´ Ù…Ù…Ù„ÙƒÙ‡ Ø³Ø¹ÙˆØ¯ Ø§Ù†Øª Ø§ØµÙ‡ ÙˆØ§Ù„Ù„ Ø·Ù„Ø¹ Ù…Ù†Ùƒ Ø³Ø¹Ø¯ Ø¹Ø´ØªÙ… Ø¹Ø§Ø´ Ø¨Ù†Ø§Ù† Ø¹Ø§Ø´ Ù…Ù…Ù„ÙƒÙ‡ Ø³Ø¹ÙˆØ¯ÙŠÙ‡ Ø§Ù„Ù„Ù‡ ÙŠØ­Ù… ÙŠÙ†ØµØ± ÙŠÙ†ØµØ± ÙÙŠÙƒ Ø§Ù†Øª Ø§ØµÙ‡ ÙˆØ§Ù„Ù„ Ø·Ù„Ø¹ Ù…Ù†Ùƒ Ø³Ø¹Ø¯ Ø¹Ø´ØªÙ… Ø¹Ø§Ø´ Ø¨Ù†Ø§Ù† Ø¹Ø§Ø´ Ù…Ù…Ù„ÙƒÙ‡ Ø³Ø¹ÙˆØ¯ÙŠÙ‡                                           |POS     |[0.997965257704871,0.001483654632293707,5.510876628353509E-4] |1.0  |0.0       |\n",
      "|Ø³Ø¹ÙˆØ¯ÙŠÙ‡ ØµÙÙŠØ­ Ù‡ÙŠØ¨ Ø³Ø§Ø® Ù…ØªÙØ¬Ø± Ù‚ÙˆØ§Ø³ Ø§ÙˆØ§Ø¯ Ø¯Ø§Ø®Ù„ Ø®Ø§Ø±Ø¬ ØªØ¯ÙØ¹ Ø«Ù…Ù† Ø§Ø±Ù‡Ø§Ø¨ Ø§ÙŠØ¯ ÙˆÙƒÙ„ ÙŠØ­ØµÙ„ Ù‡Ùˆ Ù…Ù‚Ø¯Ù…Ù‡ ÙˆØ§Ù„Ø§Øª Ø§Ø¹Ø¸Ù…Ø§Ù„Ø³Ø¹ÙˆØ¯ ØµÙÙŠØ­ Ù‡ÙŠØ¨ Ø³Ø§Ø®                                                                                                                                                                                                                                                                                                                                                     |NEG     |[0.9904186109903172,0.005773823735438283,0.003807565274244601]|0.0  |0.0       |\n",
      "|Ø­ÙƒÙˆÙ…Ù‡ Ù„Ø¨Ù†Ø§Ù†ÙŠÙ‡ Ù…Ø¹Ù† Ø¨Ø§Ù„Ø±Ø¯ Ø«Ø§Ù…Ø± Ø³Ø¨Ù‡ Ù‡Ø¯Ø¯ Ø¨Ù†Ø§Ù† ØªÙ‡Ø¯ÙŠØ¯ Ù…Ø¨Ø§Ø´Ø± Ø¹Ù„Ù†ÙŠ Ø§Ø¹Ø§Ø¯ Ø¨Ù†Ø§Ù† Ø§ØªÙˆÙ† Ø­Ø±Ø¨ Ø§Ù‡Ù„ÙŠÙ‡ Ø³Ø§Ø¨Ù‚Ù‡ Ø¹Ø§Ù‚Ù„ ÙŠÙÙ‡Ù…                                                                                                                                                                                                                                                                                                                                                                  |NEG     |[0.9839370769928797,0.008650751177544885,0.0074121718295755]  |0.0  |0.0       |\n",
      "|Ø­Ù…Ø¯Ø§Ù„Ù„Ù‡ Ø­ØµÙ„ Ù…Ø±ÙƒØ² Ø«Ø§Ù„Ø« Ù…Ø±ÙƒØ² Ø§ÙˆÙ„ Ø³Ø¨Ø§Ù‚ ÙˆØ§Ø¯ Ø±Ù… Ø¯ÙˆÙ„ Ø§Ø±Ø¯ Ù…Ø³Ø§Ù 42 ÙƒÙŠÙ„Ùˆ Ù…ØªØ±  Ø­ØµÙ„ Ø§Ø®Ùˆ ÙŠØµÙ„â€¦ Ø³Ø¨Ø§Ù‚ ÙˆØ§Ø¯ Ø±Ù… Ø¯ÙˆÙ„                                                                                                                                                                                                                                                                                                                                                                    |POS     |[0.9826775886577622,0.01322553843379004,0.004096872908447653] |1.0  |0.0       |\n",
      "|ÙˆØ§Ù†Ø§ Ø´Ø§Ù‡Ø¯ Ù…Ù†Ø¸Ø± ÙˆÙ‚Ù„ Ù„Ù†ÙØ³ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ÙŠâœ‹ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ÙŠâœ‹ ÙˆØ§Ù†Ø§ Ø´Ø§Ù‡Ø¯ Ù…Ù†Ø¸Ø± ÙˆÙ‚Ù„ Ù„Ù†ÙØ³ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨ Ø¸Ø± ÙˆÙ‚Ù„ Ù„Ù†ÙØ³ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠ |NEG     |[0.9750859050797639,9.813348930577917E-5,0.024815961430930122]|0.0  |0.0       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+--------------------------------------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression using TF-IDF Features\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline = Pipeline(stages=[regexTokenizer, hashingTF, idf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(5,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.6729132795659876\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",metricName=\"f1\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|             1151|\n",
      "|       1.0|              597|\n",
      "|       2.0|              283|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 68.390%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation\n",
    "pipeline = Pipeline(stages=[regexTokenizer,countVectors, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "             .build())\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "predictions = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+---------------------------------------------------------------+-----+----------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |Category|probability                                                    |label|prediction|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+---------------------------------------------------------------+-----+----------+\n",
      "|ÙˆØ§Ù†Ø§ Ø´Ø§Ù‡Ø¯ Ù…Ù†Ø¸Ø± ÙˆÙ‚Ù„ Ù„Ù†ÙØ³ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ÙŠâœ‹ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ÙŠâœ‹ ÙˆØ§Ù†Ø§ Ø´Ø§Ù‡Ø¯ Ù…Ù†Ø¸Ø± ÙˆÙ‚Ù„ Ù„Ù†ÙØ³ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨Ø¹Ø¬Ø¨ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠÙ† Ø®ÙŠØ± Ø§Ø³Ù„Ø§Ù… Ø¨ Ù„Ø§Ø¯ Ø´Ù‡Ø§Ù…Ù‡ ÙƒØ±Ù… Ø¹Ø±Ø¨ Ø¸Ø± ÙˆÙ‚Ù„ Ù„Ù†ÙØ³ ÙŠØ­Ø¯Ø« Ø¨Ù…Ù‡ Ø§Ù†Ø³Ø§Ù†ÙŠÙ‡ Ø§Ù„Ø·Ø¨ Ø¨ Ø¯ÙŠ |NEG     |[0.9999988475590554,8.102816688367889E-7,3.421592759446772E-7] |0.0  |0.0       |\n",
      "|Ø§Ø­ØªÙ„Ø§Ù„ ÙŠØ­ÙƒÙ… Ø¨Ø§Ù„Ø³Ø¬ Ù…ÙˆØ¨Ø¯ ØºØ±Ø§Ù… Ù‚ÙŠÙ… Ø§Ù„Ù Ø´ÙŠÙ‚Ù„ Ø§Ø®Ùˆ Ù†ØµØ± Ø§ÙƒØ±Ù… Ø¨Ø¯Ùˆ ØªÙ†ÙÙŠØ° Ø³Ù„Ø³Ù„ Ø¹Ù…Ù„ÙŠØ§â€¦ Ø§Ø­ØªÙ„Ø§Ù„ ÙŠØ­ÙƒÙ… Ø¨Ø§Ù„Ø³Ø¬ Ù…ÙˆØ¨Ø¯ ØºØ±Ø§Ù…                                                                                                                                                                                                                                                                                                                                                              |NEG     |[0.9988106975466617,5.286095568034762E-4,6.606928965347219E-4] |0.0  |0.0       |\n",
      "|Ø§ÙƒØ± ÙˆØ§Ø­Ø¯ ÙŠØ­Ú† Ø¹ ÙˆØ§Ø­Ø¯ Ø§Ø¹Ø±Ù Ú¯Ø¯Ø§Ù… Ø¹Ù†Ø¯ Ø¬Ø±Ø§Ù‡ Ø§Ù†Ùˆ Ø§Ú¯Ù„ Ø§Ø³Ùƒ ÙˆØ§Ù†Ø¬Ø¨ Ø§Ù†Ø§ Ù†ÙˆØ¹ÙŠÙ‡ Ø§Ù„ ÙŠÙ†Ù‚Ù„ Ø­Ú† Ø­ÙŠØ« Ø§Ø±ÙˆØ­ Ù„Ù„Ø«â€¦ ÙˆØ§Ø­Ø¯ ÙŠØ­Ú† Ø¹ ÙˆØ§Ø­Ø¯ Ø§Ø¹Ø±Ù Ú¯Ø¯Ø§Ù… Ø¹Ù†Ø¯ Ø¬Ø±Ø§Ù‡ Ø§ÙƒØ± ÙˆØ§Ø­Ø¯ ÙŠØ­Ú† Ø¹ ÙˆØ§Ø­Ø¯ Ø§Ø¹Ø±Ù Ú¯Ø¯Ø§Ù… Ø§ÙƒØ± ÙˆØ§Ø­Ø¯ ÙŠØ­Ú† Ø¹ ÙˆØ§Ø­Ø¯ Ø§Ø¹Ø±Ù Ú¯Ø¯Ø§Ù… Ø¹Ù†Ø¯ Ø¬Ø±Ø§Ù‡ Ø§Ù†Ùˆ Ø§Ú¯Ù„ Ø§Ø³Ùƒ ÙˆØ§Ù†Ø¬Ø¨ Ø§Ù†Ø§ Ù†ÙˆØ¹ÙŠÙ‡ Ø§Ù„ ÙŠÙ†Ù‚Ù„ Ø­Ú† Ø­ÙŠØ« Ø§Ø±ÙˆØ­ Ø§ÙƒØ± ÙˆØ§Ø­Ø¯ ÙŠØ­Ú† Ø¹ ÙˆØ§Ø­Ø¯ Ø§Ø¹Ø±Ù Ú¯Ø¯Ø§Ù… Ø¹Ù†Ø¯ Ø¬Ø±Ø§Ù‡ Ø§Ù†Ùˆ Ø§Ú¯Ù„ Ø§Ø³Ùƒ ÙˆØ§Ù†Ø¬Ø¨ Ø§Ù†Ø§ Ù†ÙˆØ¹ÙŠÙ‡ Ø§Ù„ ÙŠÙ†Ù‚Ù„ Ø­Ú† Ø­ÙŠØ« Ø§Ø±ÙˆØ­ Ù„Ù„Ø«â€¦                                                                                                                      |NEG     |[0.9949999628129137,0.0015839266028577085,0.003416110584228445]|0.0  |0.0       |\n",
      "|Ø§ÙŠÙ‡ ÙˆØ§Ù„Ù„ ğŸ˜” ğŸ’” Ø±Ø¨ ÙŠØºÙØ± ÙŠØ±Ø­Ù… ÙˆÙŠØ³ Ø³ÙŠØ­ Ø¬Ù†Ø§ ÙŠØºÙØ± Ù„Ø§Ø¨ ÙŠØ¬Ù…Ø¹ Ø¬Ù†Ø§ Ù†Ø¹ÙŠÙ… ÙŠØ§Ø±Ø¨ Ø¹Ø§Ù„Ù…                                                                                                                                                                                                                                                                                                                                                                                             |NEG     |[0.9948971207755846,0.0028872629753925187,0.002215616249023]   |0.0  |0.0       |\n",
      "|Ø§Ù…Ø±ÙŠÙƒ Ø¯Ù„ÙˆÙ‚Øª Ù…Ø­Ø· Ù†ÙˆÙˆÙŠÙ‡ Ø´ØºØ§Ù„ Ø±Ø§Ù…Ø¬ ÙØ¶Ø§Ø¡ Ø´ØºØ§Ù„ Ø§Ø¨Ø­Ø§Ø« Ø¹Ù„Ù…ÙŠÙ‡ Ø§Ø³ØªØ¯ÙŠÙˆÙ‡Ø§ Ù…ØµØ§Ù†Ø¹ Ø§Ø­Ø²Ø§Ø¨ Ø­Ø±ÙƒØ§ Ø±ÙØ¶Ø§Ù†Øª Ø¨Ù‚ÙŠ Ø´ØºØ§Ù„ Ø§ÙŠÙ‡                                                                                                                                                                                                                                                                                                                                                                  |NEG     |[0.9925834000904248,0.002792508860418991,0.004624091049156041] |0.0  |0.0       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+---------------------------------------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.7104643740264259\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|             1081|\n",
      "|       1.0|              616|\n",
      "|       2.0|              334|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 71.590%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
