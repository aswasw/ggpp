{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7992"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "jobDir = \"tweets1.json\"\n",
    "tweets = spark.read.json([jobDir])\n",
    "tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets = tweets.select(\"text\", \\\n",
    "                     \"Category\" )\n",
    "\n",
    "tweets.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Pipeline\n",
    "from pyspark.ml.feature import RegexTokenizer,CountVectorizer\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "\n",
    "countVectors = CountVectorizer(inputCol=\"words\", outputCol=\"features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+--------+-----------------------------------------------------------+----------------------------------------------------------------------------------------------+-----+\n",
      "|                                             text|Category|                                                      words|                                                                                      features|label|\n",
      "+-------------------------------------------------+--------+-----------------------------------------------------------+----------------------------------------------------------------------------------------------+-----+\n",
      "|               والل عجب عشان كتاب انجليز صعب كلم |     POS|                  [والل, عجب, عشان, كتاب, انجليز, صعب, كلم]|                          (17072,[68,109,147,351,644,1456,6074],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])|  2.0|\n",
      "|               انه مفيد جدان انا اتعلم كثير اشيء |     POS|                  [انه, مفيد, جدان, انا, اتعلم, كثير, اشيء]|                       (17072,[19,22,126,3800,9802,13014,16094],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])|  2.0|\n",
      "|           انه رنامج رايع يترجم كلم قطع باقص سرع |     POS|             [انه, رنامج, رايع, يترجم, كلم, قطع, باقص, سرع]|               (17072,[19,147,242,251,1087,2266,3234,14862],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|  2.0|\n",
      "|            رنامج جميل جدا يترجم كلم جمل فعل روع |     POS|              [رنامج, جميل, جدا, يترجم, كلم, جمل, فعل, روع]|                 (17072,[82,127,147,166,242,1341,3234,3282],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|  2.0|\n",
      "|قمه روعه الف شكر تقدير مجهود نافع جدا تحي احترام |     POS|[قمه, روعه, الف, شكر, تقدير, مجهود, نافع, جدا, تحي, احترام]|(17072,[82,97,103,398,635,1202,2404,4552,6402,7219],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|  2.0|\n",
      "|                         جميل اشخاص ايجد انجلزيه |     POS|                               [جميل, اشخاص, ايجد, انجلزيه]|                                               (17072,[166,881,14206,16489],[1.0,1.0,1.0,1.0])|  2.0|\n",
      "|                             عاش ايد برنامج رايع |     POS|                                   [عاش, ايد, برنامج, رايع]|                                                   (17072,[251,332,459,756],[1.0,1.0,1.0,1.0])|  2.0|\n",
      "|                         برنامج حلوو وانصح تحميل |     POS|                               [برنامج, حلوو, وانصح, تحميل]|                                              (17072,[459,3115,11912,15240],[1.0,1.0,1.0,1.0])|  2.0|\n",
      "|                        حلو والل صرت احل واجب ال |     POS|                            [حلو, والل, صرت, احل, واجب, ال]|                                   (17072,[14,68,262,917,3873,5354],[1.0,1.0,1.0,1.0,1.0,1.0])|  2.0|\n",
      "|                                 برنامج جدا جميل |     POS|                                        [برنامج, جدا, جميل]|                                                            (17072,[82,166,459],[1.0,1.0,1.0])|  2.0|\n",
      "+-------------------------------------------------+--------+-----------------------------------------------------------+----------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[regexTokenizer, countVectors, label_stringIdx])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "dataset.show(10,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 5654\n",
      "Test Dataset Count: 2335\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+-----+----------+\n",
      "|                          text|Category|label|prediction|\n",
      "+------------------------------+--------+-----+----------+\n",
      "|2 باب ازهر شيخ كنيسه دعامت ...|     NEG|  0.0|       1.0|\n",
      "|2 متحدث عسكر يعترف قيام جيش...| NEUTRAL|  1.0|       1.0|\n",
      "|«ونظر موسي الي شمال جبال بن...| NEUTRAL|  1.0|       1.0|\n",
      "|«ونظر موسي الي شمال جبال بن...| NEUTRAL|  1.0|       1.0|\n",
      "|                  اا سلام روح |     NEG|  0.0|       1.0|\n",
      "|اب هرير رض الله عنه رسول ال...| NEUTRAL|  1.0|       1.0|\n",
      "|ابار سعاد مستشار بامار منطق...|     POS|  2.0|       1.0|\n",
      "|ابار سعاد مستشار بامار منطق...|     POS|  2.0|       1.0|\n",
      "|   ابانوب سمير مصاب طلق خرطوش | NEUTRAL|  1.0|       1.0|\n",
      "|         ابعد عنهم انتاش قدهم | NEUTRAL|  1.0|       1.0|\n",
      "+------------------------------+--------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LinearSVC(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(trainingData)\n",
    "\n",
    "# score the model on test data.\n",
    "predictions = ovrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"text\",\"Category\",\"label\",\"prediction\") \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6444058429485806"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pyspark.ml.feature import HashingTF, IDF\\nhashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\\npipeline = Pipeline(stages=[regexTokenizer, hashingTF, idf, label_stringIdx])\\npipelineFit = pipeline.fit(tweets)\\ndataset = pipelineFit.transform(tweets)\\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\\n\\nlr = LinearSVC(maxIter=10, tol=1E-6, fitIntercept=True)\\n# instantiate the One Vs Rest Classifier.\\novr = OneVsRest(classifier=lr)\\n\\n# train the multiclass model.\\novrModel = ovr.fit(trainingData)\\n\\n# score the model on test data.\\npredictions = ovrModel.transform(testData)\\n\\npredictions.filter(predictions[\\'prediction\\'] == 1)     .select(\"text\",\"Category\",\"label\",\"prediction\")     .show(n = 10, truncate = 30) '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from pyspark.ml.feature import HashingTF, IDF\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline = Pipeline(stages=[regexTokenizer, hashingTF, idf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "\n",
    "lr = LinearSVC(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(trainingData)\n",
    "\n",
    "# score the model on test data.\n",
    "predictions = ovrModel.transform(testData)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"text\",\"Category\",\"label\",\"prediction\") \\\n",
    "    .show(n = 10, truncate = 30) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6444058429485806"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " '''from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|        1085|\n",
      "|  1.0|         600|\n",
      "|  2.0|         650|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pl.groupby('label').agg({'label': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|             1144|\n",
      "|       1.0|              575|\n",
      "|       2.0|              616|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 64.582%\n"
     ]
    }
   ],
   "source": [
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
