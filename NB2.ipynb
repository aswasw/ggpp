{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9988"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the json FIle contain tweets and there labes \n",
    "#For train and test\n",
    "from pyspark.sql import SparkSession\n",
    "jobDir = \"tweets111.json\"\n",
    "tweets = spark.read.json([jobDir])\n",
    "tweets.count() #number of tweets in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select the object in json file\n",
    "tweets = tweets.select(\"text\", \\\n",
    "                     \"Category\" )\n",
    "\n",
    "tweets.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer,CountVectorizer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "#convert a collection of text documents to vectors of token counts. \n",
    "countVectors = CountVectorizer(inputCol=\"words\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "|text                                             |Category|words                                                      |label|features                                                                                      |\n",
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "|ÙˆØ§Ù„Ù„ Ø¹Ø¬Ø¨ Ø¹Ø´Ø§Ù† ÙƒØªØ§Ø¨ Ø§Ù†Ø¬Ù„ÙŠØ² ØµØ¹Ø¨ ÙƒÙ„Ù…                |POS     |[ÙˆØ§Ù„Ù„, Ø¹Ø¬Ø¨, Ø¹Ø´Ø§Ù†, ÙƒØªØ§Ø¨, Ø§Ù†Ø¬Ù„ÙŠØ², ØµØ¹Ø¨, ÙƒÙ„Ù…]                  |1.0  |(19722,[47,92,176,419,588,1350,6837],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                           |\n",
      "|Ø§Ù†Ù‡ Ø±Ù†Ø§Ù…Ø¬ Ø±Ø§ÙŠØ¹ ÙŠØªØ±Ø¬Ù… ÙƒÙ„Ù… Ù‚Ø·Ø¹ Ø¨Ø§Ù‚Øµ Ø³Ø±Ø¹            |POS     |[Ø§Ù†Ù‡, Ø±Ù†Ø§Ù…Ø¬, Ø±Ø§ÙŠØ¹, ÙŠØªØ±Ø¬Ù…, ÙƒÙ„Ù…, Ù‚Ø·Ø¹, Ø¨Ø§Ù‚Øµ, Ø³Ø±Ø¹]             |1.0  |(19722,[22,176,291,308,1180,2074,2930,12880],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])               |\n",
      "|Ø±Ù†Ø§Ù…Ø¬ Ø¬Ù…ÙŠÙ„ Ø¬Ø¯Ø§ ÙŠØªØ±Ø¬Ù… ÙƒÙ„Ù… Ø¬Ù…Ù„ ÙØ¹Ù„ Ø±ÙˆØ¹             |POS     |[Ø±Ù†Ø§Ù…Ø¬, Ø¬Ù…ÙŠÙ„, Ø¬Ø¯Ø§, ÙŠØªØ±Ø¬Ù…, ÙƒÙ„Ù…, Ø¬Ù…Ù„, ÙØ¹Ù„, Ø±ÙˆØ¹]              |1.0  |(19722,[99,116,135,176,308,1497,2930,3764],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                 |\n",
      "|Ù‚Ù…Ù‡ Ø±ÙˆØ¹Ù‡ Ø§Ù„Ù Ø´ÙƒØ± ØªÙ‚Ø¯ÙŠØ± Ù…Ø¬Ù‡ÙˆØ¯ Ù†Ø§ÙØ¹ Ø¬Ø¯Ø§ ØªØ­ÙŠ Ø§Ø­ØªØ±Ø§Ù… |POS     |[Ù‚Ù…Ù‡, Ø±ÙˆØ¹Ù‡, Ø§Ù„Ù, Ø´ÙƒØ±, ØªÙ‚Ø¯ÙŠØ±, Ù…Ø¬Ù‡ÙˆØ¯, Ù†Ø§ÙØ¹, Ø¬Ø¯Ø§, ØªØ­ÙŠ, Ø§Ø­ØªØ±Ø§Ù…]|1.0  |(19722,[97,99,108,485,768,1231,1763,2351,4526,5724],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|Ø¬Ù…ÙŠÙ„ Ø§Ø´Ø®Ø§Øµ Ø§ÙŠØ¬Ø¯ Ø§Ù†Ø¬Ù„Ø²ÙŠÙ‡                          |POS     |[Ø¬Ù…ÙŠÙ„, Ø§Ø´Ø®Ø§Øµ, Ø§ÙŠØ¬Ø¯, Ø§Ù†Ø¬Ù„Ø²ÙŠÙ‡]                               |1.0  |(19722,[116,707,17003,18478],[1.0,1.0,1.0,1.0])                                               |\n",
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import  StringIndexer\n",
    "#StringIndexer encodes a string column of labels to a column of label indices.\n",
    "label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "#pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, label_stringIdx, countVectors])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "dataset.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 7957\n",
      "Test Dataset Count: 2031\n"
     ]
    }
   ],
   "source": [
    "#Partition Training & Test sets\n",
    "#80% train ,20% test\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------+-----+----------+\n",
      "|text                                                                                                    |Category|probability                                                  |label|prediction|\n",
      "+--------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------+-----+----------+\n",
      "|Ø§Ø­Ù„ÙŠ ÙŠÙ†Ø¨Ø³Ø· ğŸ˜” ğŸ’˜                                                                                        |NEG     |[0.48608193125261606,0.5132334485666692,6.846201807147622E-4]|0.0  |1.0       |\n",
      "|ÙŠØ­ØªØ§Ø¬ ØªÙÙ‡Ù… Ø¯Ø¹Ù… Ù…Ø³Ø§Ù†Ø¯ Ø§Ø®Ø° Ø§ÙŠØ¯ ØªÙˆÙÙŠØ± Ù…Ø®ØªØµ Ù…ÙˆÙ‡Ù„ ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ù… Ù…Ø¯Ø§Ø±Ø³ Ø±ÙˆØ¶Ø§ ÙˆÙ† â€¦                                 |NEG     |[0.4762008480903491,0.5193832645538984,0.004415887355752598] |0.0  |1.0       |\n",
      "|Ø§Ù…ÙˆØ± Ù‡Ø§Ù…Ù‡ Ù„ØªÙ†Ù… Ø²ÙˆØ¬ ØªÙØ§Ø¹Ù„ Ø§Ø²Ù…Ø§ Ø´Ø±ÙŠ Ù„Ø°Ù„ Ø§Ø«Ø± ÙƒØ¨ÙŠØ± Ù†Ø§Ø¡ Ù…ÙˆØ¯Ù‡ Ø²ÙˆØ¬ Ø¬Ø¹Ù„ Ù‚Ø±Ø¨ Ù…Ø­Ø¨                                 |POS     |[0.4758145885091393,0.5066747631396664,0.01751064835119432]  |1.0  |1.0       |\n",
      "|Ø¹Ù†Ø¯Ù… ØµØ¹Ø¯ Ù†ÙŠÙ„ Ø§Ø±Ù…Ø³ØªØ±ÙˆÙ†Ø¬ Ø³Ø·Ø­ Ù‚Ù…Ø± Ù‚Ø±Ø± ÙŠÙƒÙˆÙ† Ø§Ø³Ù‡Ø§Ù… Ø­Ø¶Ø§Ø± Ø§ØµØ¯Ø§Ø± Ø§Ø´Ø§Ø¹ Ø§Ù†Ù‡ Ø³Ù…Ø¹ Ø§Ù„Ø§Ø° Ø§Ø³Ù„Ù…Ø§Ù„Ø§Ø´Ø§Ø¹ Ø§ÙˆÙØ± ÙƒØªÙŠØ± Ù‡Ø¯Ù Ø®ÙŠØ± |NEG     |[0.4722030310050228,0.48205083845646146,0.045746130538515666]|0.0  |1.0       |\n",
      "|ÙƒØ¨ÙŠØ± Ù‚Ø¶Ø§Ù‡ ÙŠØªÙ‡Ù… Ø¨ Ø³Ø§Ø¯ Ø¶Ù…ÙŠØ± ÙŠØªØ¹Ù‡Ø¯ ØµÙˆÙ† ÙƒØ±Ø§Ù… Ø§ØªØ±Ø§Ùƒ Ø­Ø±ÙŠØ§                                                     |POS     |[0.4716136616597137,0.5037672865973535,0.02461905174293288]  |1.0  |1.0       |\n",
      "+--------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NaiveBayes Count Vector Features\n",
    "nb = NaiveBayes(smoothing=1 , modelType=\"multinomial\")\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)# model will make predictions and score on the test set\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"text\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.6978025729777162\n"
     ]
    }
   ],
   "source": [
    "# Show the accuracy \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              952|\n",
      "|       1.0|              685|\n",
      "|       2.0|              394|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 70.015%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------+--------+---------------------------------------------------------------+-----+----------+\n",
      "|text                                                                                |Category|probability                                                    |label|prediction|\n",
      "+------------------------------------------------------------------------------------+--------+---------------------------------------------------------------+-----+----------+\n",
      "|ğŸ“® ÙŠØ¹Ø±Ù ÙŠØªÙ…Ù†ÙŠ Ø®ÙŠØ±   ğŸ¥€                                                              |NEG     |[0.49799508256428204,0.502004917433727,1.9910373682703385E-12] |0.0  |1.0       |\n",
      "|Ø§Ø³ÙˆØ§Ù† Ø±ÙŠÙŠØ³ ØªØ¸Ù† ÙƒØ°Ø¨ ÙŠØ¶Ø±ÙƒØ¨Ø§Ù„Ø¹ÙƒØ³Ø§Ù„ÙƒØ°Ø¨ Ø§Ø°Ø§ ØªÙƒØ±Ø± ÙƒØ«Ø§Ù ÙŠÙˆØ¯ÙŠ Ø§Ù„ÙŠ ØªØ´ÙˆÙŠØ´ Ø§Ø°Ù‡Ø§Ù† Ù†Ø§Ø³ Ù…Ù‚Ø§Ù„ ÙƒØ§Ù…Ù„ |NEUTRAL |[0.45819918873525817,0.5418008111672028,9.753889349239166E-11] |2.0  |1.0       |\n",
      "|Ù„Ù‡Ù… Ø­Ø³Ø¨ ØªØ¶ÙŠÙ‚ Ø­ÙŠØ§Ù‡  ÙˆØ§Ù† Ù…Ù†ØªØµØ± ÙŠØºÙ„Ø¨ ÙˆØ¬Ø¹  Ù„Ù‡Ù… Ø¹ÙˆÙ† Ù†Ø¬Ø§Øª Ø§ÙÙ‚Ø¯ Ø­ÙŠÙ„Ù‡ ğŸ’­                    |POS     |[0.43158695499527694,0.568413045004723,1.0234500634849935E-29] |1.0  |1.0       |\n",
      "|Ø´Ø±ÙŠØ¹Ù‡ Ø§Ø­ÙƒØ§Ù… ÙƒØªØ¨ ÙˆÙØ§ Ø±Ø³ÙˆÙ„ Ù„Ø°Ù„ ØºÙ„Ø· ØªØ±Ø¨Ø· Ø´Ø®Øµ Ù…Ø´ Ø®ÙˆÙ Ø­Ø±Øµ Ù…Ø¹Ù„ÙˆÙ…Ù‡ ØªÙƒÙˆÙ† ØµØ­                 |NEUTRAL |[0.43128201589113835,0.5522257955246429,0.016492188584218907]  |2.0  |1.0       |\n",
      "|Ø´Ù‡Ø§Ù„Ø§Ù…ØªØ­ Ø²ÙØª Ø§Ù„ Ù†ÙØ³ Ø±Ø§Ø¹ ) Ø¨Ø§Ù‚ Ø¯Ù‚Ø§ÙŠÙ‚ ÙˆÙ†Ø§ Ø³ÙˆØ§Ù„ Ø¨Ø§Ù‚ Ø¬Ø¯Ø§Ù… Ø³ÙˆØ§Ù„ ØºÙŠØ± ğŸ™‚ ğŸ’”                |POS     |[0.39884438061538857,0.6011556193846115,2.8531373626477186E-35]|1.0  |1.0       |\n",
      "+------------------------------------------------------------------------------------+--------+---------------------------------------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NaiveBayes using TF-IDF Features\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "#hashingTF\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "#idf\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=2) #minDocFreq: remove sparse terms\n",
    "#pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, hashingTF, idf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "#Partition Training & Test sets\n",
    "#80% train ,20% test\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"text\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.658453687693364\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              879|\n",
      "|       1.0|              637|\n",
      "|       2.0|              515|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 65.633%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation\n",
    "pipeline = Pipeline(stages=[regexTokenizer,countVectors, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(nb.smoothing,[0.6, 0.8, 1.0])\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=nb, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "predictions = cvModel.transform(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------------------------------+-----+----------+\n",
      "|text                                                                                                                                                                                                             |Category|probability                                                       |label|prediction|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------------------------------+-----+----------+\n",
      "|Ù†ØªØ¹Ù„Ù… Ù†ØµÙŠØ­Ù‡ Ù†ØªØ¹Ù„Ù… Ø§Ø®Ø·Ø§Ø¡ Ù†Ù†Ø¶Ø¬ Ù…Ø±ÙˆØ± Ø¹Ù…Ø± Ù…Ø±ÙˆØ± Ø§ÙˆØºØ§Ø¯ Ø­ÙŠØ§ Ù…Ø§Ù‡Ùˆ ÙƒÙ„Ø§Ù… ÙŠØ¨Ø§Ø¹ Ø¯ÙˆØ±Ø§ ØªÙ†Ù…ÙŠÙ‡ Ø¨Ø´Ø±ÙŠØ©Ù†ØªØ¹Ù„Ù… Ø§Ø®Ø·Ø§Ø¡ Ù†Ù†Ø¶Ø¬ Ù…Ø±ÙˆØ± Ø¹Ù…Ø± Ù…Ø±ÙˆØ± Ø§ÙˆØºØ§Ø¯ Ø­Ù† Ù†ØªØ¹Ù„Ù… Ù†ØµÙŠØ­Ù‡ Ù†ØªØ¹Ù„Ù… Ø§Ø®Ø·Ø§Ø¡ Ù†Ù†Ø¶Ø¬ Ù…Ø±ÙˆØ± Ø¹Ù…Ø± Ù…Ø±ÙˆØ± Ø§ÙˆØºØ§Ø¯ Ø­ÙŠØ§ ÙƒÙ„Ø§Ù… ÙŠØ¨Ø§Ø¹ Ø¯ÙˆØ±Ø§ ØªÙ†Ù…ÙŠÙ‡ Ø¨Ø´Ø±ÙŠÙ‡ ØªÙ‡ÙƒÙ… |NEG     |[0.9999999997477849,7.378283050347505E-15,2.522077624984827E-10]  |0.0  |0.0       |\n",
      "|ÙŠØ§Ø­Ù…Ø§Ø± ÙŠØ§Ø³Ø¹ÙˆØ¯ Ø¨Ø¯Ùƒ ØªØ¨Ù‚ÙŠ Ø­Ù…Ø§Ø± Ù…Ù„ÙŠØ§Ø±Ø§ Ø¨Ø· Ø§Ù…Ø±Ø§Ø¡ Ø¯Ø¹Ø§Ø¡ ÙŠÙÙŠØ¯ Ø¯Ù„ÙŠÙ„ Ù…Ù‚Ø¯Ø³Ø§ Ø¨Ø§Ø±Ùƒ Ø§Ù…Ù† ØµÙˆÙ„ ØµØ§Ø±ÙˆØ® Ø¨Ùˆ ÙŠÙ…Ù† Ù„Ù‡Ø¯Ù Ø­Ø±Ù… Ø®Ø§Ø¯Ù… Ø·Ø´ ØªØ¨Ù‚ÙŠ Ø­Ù…Ø§Ø± Ù…Ù„ÙŠØ§Ø±Ø§ Ø¨Ø·                                                                                  |NEG     |[0.9999999995248321,2.9966830502380053E-10,1.7549966070894897E-10]|0.0  |0.0       |\n",
      "|Ø³Ø¹ÙˆØ¯ÙŠÙ‡ ØµÙÙŠØ­ Ù‡ÙŠØ¨ Ø³Ø§Ø® Ù…ØªÙØ¬Ø± Ù‚ÙˆØ§Ø³ Ø§ÙˆØ§Ø¯ Ø¯Ø§Ø®Ù„ Ø®Ø§Ø±Ø¬ ØªØ¯ÙØ¹ Ø«Ù…Ù† Ø§Ø±Ù‡Ø§Ø¨ Ø§ÙŠØ¯ ÙˆÙƒÙ„ ÙŠØ­ØµÙ„ Ù‡Ùˆ Ù…Ù‚Ø¯Ù…Ù‡ ÙˆØ§Ù„Ø§Øª Ø§Ø¹Ø¸Ù…Ø§Ù„Ø³Ø¹ÙˆØ¯ ØµÙÙŠØ­ Ù‡ÙŠØ¨ Ø³Ø§Ø®                                                                                                 |NEG     |[0.9999999993171966,3.2465723307075296E-14,6.827710127039229E-10] |0.0  |0.0       |\n",
      "|Ø¹Ø§Ù‚Ù„ Ù…ÙˆÙ… Ø¨Ø§Ù„Ù„Ù‡ Ø¯ÙˆÙ† Ø¹ÙˆØ¯ ÙŠØ§Ù…Ù„ ÙŠØªÙ…Ù†ÙŠ Ø§Ù† ØªÙ‚ØµÙ ØµÙˆØ§Ø±ÙŠØ® Ø§Ø¨Ùˆ ÙŠÙ…Ù† ÙƒØ¹Ø¨Ù‡ Ø­Ø±Ù… ÙˆÙ…Ùƒ ÙŠØ¨Ù‚ Ù…Ø·ÙŠ Ø²Ø±ÙŠØ¹ Ø®Ù†Ø§Ø²ÙŠØ± ÙˆÙ‡Ø§Ø¨ Ù„Ø³Ù Ø¯Ù…Ù†Ø§Ø®Ù†Ø§Ø²ÙŠØ± ÙˆÙ‡Ø§Ø¨                                                                                               |NEG     |[0.9999999990827411,4.039977000600923E-10,5.132612731481449E-10]  |0.0  |0.0       |\n",
      "|Ø¹ Ø³ÙŠØ± Ø¨ØªØ± Ø§ÙŠØ¯ Ø¹Ù‚Ø§Ø¨ Ø§ÙƒØªØ± Ø´ÙŠ ÙŠÙ„Ø¹Ø¨ ØµØ§Ø¨ÙŠØ¹ Ø§Ø¬Ø±ÙŠÙ† Ø³ØªØ¹ÙŠØ¯ Ù‚ÙˆÙ„ Ø¬Ø±ÙŠØ± ÙØ±Ø²Ø¯Ù‚ Ø²Ø¹Ù… ÙØ±Ø²Ø¯Ù‚ ÙŠÙ‚ØªÙ„ Ù…Ø±Ø¨Ø¹ ÙØ§Ø¨Ø´Ø± Ø·ÙˆÙ„ Ø³Ù„Ø§Ù… Ù…Ø±Ø¨Ø¹                                                                                                         |NEG     |[0.999999998759562,1.0339498812463353E-10,1.1370428927306122E-9]  |0.0  |0.0       |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.6940235476582404\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              871|\n",
      "|       1.0|              675|\n",
      "|       2.0|              485|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 69.325%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
