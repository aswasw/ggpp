{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9988"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the json FIle contain tweets and there labes \n",
    "#For train and test\n",
    "from pyspark.sql import SparkSession\n",
    "jobDir = \"tweets111.json\"\n",
    "tweets = spark.read.json([jobDir])\n",
    "tweets.count() #number of tweets in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select the object in json file\n",
    "tweets = tweets.select(\"text\", \\\n",
    "                     \"Category\" )\n",
    "\n",
    "tweets.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer,CountVectorizer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "#convert a collection of text documents to vectors of token counts. \n",
    "countVectors = CountVectorizer(inputCol=\"words\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "|text                                             |Category|words                                                      |label|features                                                                                      |\n",
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "|والل عجب عشان كتاب انجليز صعب كلم                |POS     |[والل, عجب, عشان, كتاب, انجليز, صعب, كلم]                  |1.0  |(19722,[47,92,176,419,588,1350,6837],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                           |\n",
      "|انه رنامج رايع يترجم كلم قطع باقص سرع            |POS     |[انه, رنامج, رايع, يترجم, كلم, قطع, باقص, سرع]             |1.0  |(19722,[22,176,291,308,1180,2074,2930,12880],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])               |\n",
      "|رنامج جميل جدا يترجم كلم جمل فعل روع             |POS     |[رنامج, جميل, جدا, يترجم, كلم, جمل, فعل, روع]              |1.0  |(19722,[99,116,135,176,308,1497,2930,3764],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                 |\n",
      "|قمه روعه الف شكر تقدير مجهود نافع جدا تحي احترام |POS     |[قمه, روعه, الف, شكر, تقدير, مجهود, نافع, جدا, تحي, احترام]|1.0  |(19722,[97,99,108,485,768,1231,1763,2351,4526,5724],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|جميل اشخاص ايجد انجلزيه                          |POS     |[جميل, اشخاص, ايجد, انجلزيه]                               |1.0  |(19722,[116,707,17003,18478],[1.0,1.0,1.0,1.0])                                               |\n",
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import  StringIndexer\n",
    "#StringIndexer encodes a string column of labels to a column of label indices.\n",
    "label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "#pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, label_stringIdx, countVectors])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "dataset.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 7957\n",
      "Test Dataset Count: 2031\n"
     ]
    }
   ],
   "source": [
    "#Partition Training & Test sets\n",
    "#80% train ,20% test\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------+-----+----------+\n",
      "|text                                                                                                    |Category|probability                                                  |label|prediction|\n",
      "+--------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------+-----+----------+\n",
      "|احلي ينبسط 😔 💘                                                                                        |NEG     |[0.48608193125261606,0.5132334485666692,6.846201807147622E-4]|0.0  |1.0       |\n",
      "|يحتاج تفهم دعم مساند اخذ ايد توفير مختص موهل تعامل معهم مدارس روضا ون …                                 |NEG     |[0.4762008480903491,0.5193832645538984,0.004415887355752598] |0.0  |1.0       |\n",
      "|امور هامه لتنم زوج تفاعل ازما شري لذل اثر كبير ناء موده زوج جعل قرب محب                                 |POS     |[0.4758145885091393,0.5066747631396664,0.01751064835119432]  |1.0  |1.0       |\n",
      "|عندم صعد نيل ارمسترونج سطح قمر قرر يكون اسهام حضار اصدار اشاع انه سمع الاذ اسلمالاشاع اوفر كتير هدف خير |NEG     |[0.4722030310050228,0.48205083845646146,0.045746130538515666]|0.0  |1.0       |\n",
      "|كبير قضاه يتهم ب ساد ضمير يتعهد صون كرام اتراك حريا                                                     |POS     |[0.4716136616597137,0.5037672865973535,0.02461905174293288]  |1.0  |1.0       |\n",
      "+--------------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NaiveBayes Count Vector Features\n",
    "nb = NaiveBayes(smoothing=1 , modelType=\"multinomial\")\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)# model will make predictions and score on the test set\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"text\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.6978025729777162\n"
     ]
    }
   ],
   "source": [
    "# Show the accuracy \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              952|\n",
      "|       1.0|              685|\n",
      "|       2.0|              394|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 70.015%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------+--------+---------------------------------------------------------------+-----+----------+\n",
      "|text                                                                                |Category|probability                                                    |label|prediction|\n",
      "+------------------------------------------------------------------------------------+--------+---------------------------------------------------------------+-----+----------+\n",
      "|📮 يعرف يتمني خير   🥀                                                              |NEG     |[0.49799508256428204,0.502004917433727,1.9910373682703385E-12] |0.0  |1.0       |\n",
      "|اسوان رييس تظن كذب يضركبالعكسالكذب اذا تكرر كثاف يودي الي تشويش اذهان ناس مقال كامل |NEUTRAL |[0.45819918873525817,0.5418008111672028,9.753889349239166E-11] |2.0  |1.0       |\n",
      "|لهم حسب تضيق حياه  وان منتصر يغلب وجع  لهم عون نجات افقد حيله 💭                    |POS     |[0.43158695499527694,0.568413045004723,1.0234500634849935E-29] |1.0  |1.0       |\n",
      "|شريعه احكام كتب وفا رسول لذل غلط تربط شخص مش خوف حرص معلومه تكون صح                 |NEUTRAL |[0.43128201589113835,0.5522257955246429,0.016492188584218907]  |2.0  |1.0       |\n",
      "|شهالامتح زفت ال نفس راع ) باق دقايق ونا سوال باق جدام سوال غير 🙂 💔                |POS     |[0.39884438061538857,0.6011556193846115,2.8531373626477186E-35]|1.0  |1.0       |\n",
      "+------------------------------------------------------------------------------------+--------+---------------------------------------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NaiveBayes using TF-IDF Features\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "#hashingTF\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "#idf\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=2) #minDocFreq: remove sparse terms\n",
    "#pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, hashingTF, idf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "#Partition Training & Test sets\n",
    "#80% train ,20% test\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"text\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.658453687693364\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              879|\n",
      "|       1.0|              637|\n",
      "|       2.0|              515|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 65.633%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation\n",
    "pipeline = Pipeline(stages=[regexTokenizer,countVectors, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(nb.smoothing,[0.6, 0.8, 1.0])\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=nb, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "predictions = cvModel.transform(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------------------------------+-----+----------+\n",
      "|text                                                                                                                                                                                                             |Category|probability                                                       |label|prediction|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------------------------------+-----+----------+\n",
      "|نتعلم نصيحه نتعلم اخطاء ننضج مرور عمر مرور اوغاد حيا ماهو كلام يباع دورا تنميه بشريةنتعلم اخطاء ننضج مرور عمر مرور اوغاد حن نتعلم نصيحه نتعلم اخطاء ننضج مرور عمر مرور اوغاد حيا كلام يباع دورا تنميه بشريه تهكم |NEG     |[0.9999999997477849,7.378283050347505E-15,2.522077624984827E-10]  |0.0  |0.0       |\n",
      "|ياحمار ياسعود بدك تبقي حمار مليارا بط امراء دعاء يفيد دليل مقدسا بارك امن صول صاروخ بو يمن لهدف حرم خادم طش تبقي حمار مليارا بط                                                                                  |NEG     |[0.9999999995248321,2.9966830502380053E-10,1.7549966070894897E-10]|0.0  |0.0       |\n",
      "|سعوديه صفيح هيب ساخ متفجر قواس اواد داخل خارج تدفع ثمن ارهاب ايد وكل يحصل هو مقدمه والات اعظمالسعود صفيح هيب ساخ                                                                                                 |NEG     |[0.9999999993171966,3.2465723307075296E-14,6.827710127039229E-10] |0.0  |0.0       |\n",
      "|عاقل موم بالله دون عود يامل يتمني ان تقصف صواريخ ابو يمن كعبه حرم ومك يبق مطي زريع خنازير وهاب لسف دمناخنازير وهاب                                                                                               |NEG     |[0.9999999990827411,4.039977000600923E-10,5.132612731481449E-10]  |0.0  |0.0       |\n",
      "|ع سير بتر ايد عقاب اكتر شي يلعب صابيع اجرين ستعيد قول جرير فرزدق زعم فرزدق يقتل مربع فابشر طول سلام مربع                                                                                                         |NEG     |[0.999999998759562,1.0339498812463353E-10,1.1370428927306122E-9]  |0.0  |0.0       |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------------------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.6940235476582404\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              871|\n",
      "|       1.0|              675|\n",
      "|       2.0|              485|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 69.325%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
