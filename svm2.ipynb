{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9988"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the json FIle contain tweets and there labes \n",
    "#For train and test\n",
    "from pyspark.sql import SparkSession\n",
    "jobDir = \"tweets111.json\"\n",
    "tweets = spark.read.json([jobDir])\n",
    "tweets.count() #number of tweets in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select the object in json file\n",
    "tweets = tweets.select(\"text\", \\\n",
    "                     \"Category\" )\n",
    "\n",
    "tweets.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Pipeline\n",
    "from pyspark.ml.feature import RegexTokenizer,CountVectorizer\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "#convert a collection of text documents to vectors of token counts. \n",
    "countVectors = CountVectorizer(inputCol=\"words\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "|text                                             |Category|words                                                      |label|features                                                                                      |\n",
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "|والل عجب عشان كتاب انجليز صعب كلم                |POS     |[والل, عجب, عشان, كتاب, انجليز, صعب, كلم]                  |1.0  |(19722,[47,92,176,419,588,1350,6837],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])                           |\n",
      "|انه رنامج رايع يترجم كلم قطع باقص سرع            |POS     |[انه, رنامج, رايع, يترجم, كلم, قطع, باقص, سرع]             |1.0  |(19722,[22,176,291,308,1180,2074,2930,12880],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])               |\n",
      "|رنامج جميل جدا يترجم كلم جمل فعل روع             |POS     |[رنامج, جميل, جدا, يترجم, كلم, جمل, فعل, روع]              |1.0  |(19722,[99,116,135,176,308,1497,2930,3764],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])                 |\n",
      "|قمه روعه الف شكر تقدير مجهود نافع جدا تحي احترام |POS     |[قمه, روعه, الف, شكر, تقدير, مجهود, نافع, جدا, تحي, احترام]|1.0  |(19722,[97,99,108,485,768,1231,1763,2351,4526,5724],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|جميل اشخاص ايجد انجلزيه                          |POS     |[جميل, اشخاص, ايجد, انجلزيه]                               |1.0  |(19722,[116,707,17003,18478],[1.0,1.0,1.0,1.0])                                               |\n",
      "+-------------------------------------------------+--------+-----------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import  StringIndexer\n",
    "#StringIndexer encodes a string column of labels to a column of label indices.\n",
    "label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "#pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, label_stringIdx, countVectors])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "dataset.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 7957\n",
      "Test Dataset Count: 2031\n"
     ]
    }
   ],
   "source": [
    "#Partition Training & Test sets\n",
    "#80% train ,20% test\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+--------+-----+----------+\n",
      "|text                                                                                                     |Category|label|prediction|\n",
      "+---------------------------------------------------------------------------------------------------------+--------+-----+----------+\n",
      "| ابدء صباح مفتاح  نيه طيبه 💕 فه مفتاح باب رزق  كلم طيبه 💕 فه مفتاح باب قلوب  يوم جميل باذ الله رب نس … |POS     |1.0  |1.0       |\n",
      "| ان تجد روحء تشب بكل شي                                                                                  |POS     |1.0  |1.0       |\n",
      "| مسا قهو ☕ 🎉 💫 💕 عشاق قهوه 😍 💛                                                                      |POS     |1.0  |1.0       |\n",
      "| وقت تحميل تعال 💕                                                                                       |POS     |1.0  |1.0       |\n",
      "|( انت  وبس ) ذكري رحيل     الله يرحم رحم واسعه يجعل مثو اعال الجن                                        |NEG     |0.0  |1.0       |\n",
      "+---------------------------------------------------------------------------------------------------------+--------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC , OneVsRest Count Vector Features\n",
    "lr = LinearSVC(maxIter=10, tol=1E-3, fitIntercept=True)\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(trainingData)\n",
    "\n",
    "# score the model on test data.\n",
    "predictions = ovrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"text\",\"Category\",\"label\",\"prediction\") \\\n",
    "    .show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.7131535469691566\n"
     ]
    }
   ],
   "source": [
    "# Show the accuracy \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              974|\n",
      "|       1.0|              675|\n",
      "|       2.0|              382|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 71.590%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+--------+-----+----------+\n",
      "|text                                                                                                     |Category|label|prediction|\n",
      "+---------------------------------------------------------------------------------------------------------+--------+-----+----------+\n",
      "|   دايم  اذا كذب خلك واثق تتراجع لان يكذب انفس يصدق )                                                    |POS     |1.0  |1.0       |\n",
      "| ابدء صباح مفتاح  نيه طيبه 💕 فه مفتاح باب رزق  كلم طيبه 💕 فه مفتاح باب قلوب  يوم جميل باذ الله رب نس … |POS     |1.0  |1.0       |\n",
      "| ان تجد روحء تشب بكل شي                                                                                  |POS     |1.0  |1.0       |\n",
      "| مسا قهو ☕ 🎉 💫 💕 عشاق قهوه 😍 💛                                                                      |POS     |1.0  |1.0       |\n",
      "| وقت تحميل تعال 💕                                                                                       |POS     |1.0  |1.0       |\n",
      "+---------------------------------------------------------------------------------------------------------+--------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC , OneVsRest using TF-IDF Features\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline = Pipeline(stages=[regexTokenizer, hashingTF, idf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "lr = LinearSVC(maxIter=10, tol=1E-3, fitIntercept=True)\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(trainingData)\n",
    "\n",
    "# score the model on test data.\n",
    "predictions = ovrModel.transform(testData)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"text\",\"Category\",\"label\",\"prediction\") \\\n",
    "    .show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.6887541535337911\n"
     ]
    }
   ],
   "source": [
    "# Show the accuracy \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              961|\n",
      "|       1.0|              668|\n",
      "|       2.0|              402|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 69.129%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation\n",
    "pipeline = Pipeline(stages=[regexTokenizer,countVectors, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "lr = LinearSVC(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5])\n",
    " #            .addGrid(lr.regParam, [10.0,1.0,0.1,0.01]) \n",
    "              .build())\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=ovr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "             \n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "predictions = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------+--------+-----+----------+\n",
      "|text                                                                               |Category|label|prediction|\n",
      "+-----------------------------------------------------------------------------------+--------+-----+----------+\n",
      "|                                                                                   |NEG     |0.0  |0.0       |\n",
      "|                                                                                   |NEG     |0.0  |0.0       |\n",
      "|                                                                                   |NEG     |0.0  |0.0       |\n",
      "|                                                                                   |NEG     |0.0  |0.0       |\n",
      "|                                                                                   |NEG     |0.0  |0.0       |\n",
      "|                                                                                   |NEUTRAL |2.0  |0.0       |\n",
      "|                                                                                   |NEUTRAL |2.0  |0.0       |\n",
      "|                                                                                   |NEUTRAL |2.0  |0.0       |\n",
      "|                                                                                   |NEUTRAL |2.0  |0.0       |\n",
      "|                                                                                   |POS     |1.0  |0.0       |\n",
      "|                                                                                   |POS     |1.0  |0.0       |\n",
      "|                                                                                   |POS     |1.0  |0.0       |\n",
      "|                                                                                   |POS     |1.0  |0.0       |\n",
      "|   دايم  اذا كذب خلك واثق تتراجع لان يكذب انفس يصدق )                              |POS     |1.0  |0.0       |\n",
      "| وقت تحميل تعال 💕                                                                 |POS     |1.0  |0.0       |\n",
      "|( انت  وبس ) ذكري رحيل     الله يرحم رحم واسعه يجعل مثو اعال الجن                  |NEG     |0.0  |0.0       |\n",
      "|( زاد جمال زاد اعداء ) و انا اقول ليش يكره 🌚 😒                                   |NEG     |0.0  |0.0       |\n",
      "|- تكون واقف حد و كراش يعد   ✋ - طريق سلامه انت 😂                                  |NEG     |0.0  |0.0       |\n",
      "|- ك  ل قيود  اغلال   هنا قيود الح  ب تقيد يرفض الح  ريه 🎶 🌸 💕                   |POS     |1.0  |0.0       |\n",
      "|- كمحب لناد نصر ضد هاشتاق ✋ - ازال لد امل بان معال مستشار ترك ال شيخ ينصف جميع ف … |NEG     |0.0  |0.0       |\n",
      "+-----------------------------------------------------------------------------------+--------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"text\",\"Category\",\"label\",\"prediction\") \\\n",
    "    .show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.7111088564461715\n"
     ]
    }
   ],
   "source": [
    "# Show the accuracy \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         940|\n",
      "|  1.0|         639|\n",
      "|  2.0|         452|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|             1004|\n",
      "|       1.0|              661|\n",
      "|       2.0|              366|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 71.492%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
