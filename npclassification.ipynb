{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7988"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the json FIle contain tweets and there labes \n",
    "#For train and test\n",
    "from pyspark.sql import SparkSession\n",
    "jobDir = \"tweets1.json\"\n",
    "tweets = spark.read.json([jobDir])\n",
    "tweets.count() #number of tweets in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select the object in json file\n",
    "tweets = tweets.select(\"text\", \\\n",
    "                     \"Category\" )\n",
    "\n",
    "tweets.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer,CountVectorizer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "#convert a collection of text documents to vectors of token counts. \n",
    "countVectors = CountVectorizer(inputCol=\"words\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------+-----+----------+\n",
      "|      text|Category|     words|label|  features|\n",
      "+----------+--------+----------+-----+----------+\n",
      "|والل عج...|     POS|[والل, ...|  2.0|(17070,...|\n",
      "|انه رنا...|     POS|[انه, ر...|  2.0|(17070,...|\n",
      "|رنامج ج...|     POS|[رنامج,...|  2.0|(17070,...|\n",
      "|قمه روع...|     POS|[قمه, ر...|  2.0|(17070,...|\n",
      "|جميل اش...|     POS|[جميل, ...|  2.0|(17070,...|\n",
      "|عاش ايد...|     POS|[عاش, ا...|  2.0|(17070,...|\n",
      "|برنامج ...|     POS|[برنامج...|  2.0|(17070,...|\n",
      "|حلو وال...|     POS|[حلو, و...|  2.0|(17070,...|\n",
      "|برنامج ...|     POS|[برنامج...|  2.0|(17070,...|\n",
      "|رايع جد...|     POS|[رايع, ...|  2.0|(17070,...|\n",
      "+----------+--------+----------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import  StringIndexer\n",
    "#StringIndexer encodes a string column of labels to a column of label indices.\n",
    "label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")\n",
    "#pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, label_stringIdx, countVectors])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "dataset.show(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 6394\n",
      "Test Dataset Count: 1594\n"
     ]
    }
   ],
   "source": [
    "#Partition Training & Test sets\n",
    "#80% train ,20% test\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------+-----+----------+\n",
      "|                                                                                                text|Category|                                                  probability|label|prediction|\n",
      "+----------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------+-----+----------+\n",
      "|          فقط جلس ود موقف رفض حوار رييس جماع حزب ملتزم موقف شارع رافض حوار دون ضمانا موقف جبه انقاذ |     NEG|   [0.49196183024734186,0.507523933392624,5.1423636003414E-4]|  0.0|       1.0|\n",
      "|                                                                                  طوارء تحسب مظاهرا | NEUTRAL| [0.489363171296104,0.49483514881304347,0.015801679890852523]|  1.0|       1.0|\n",
      "|                                                                  متحدث عمل سبوب نياب تامر حبس ميمو | NEUTRAL| [0.4723239735772685,0.5181966909959465,0.009479335426785016]|  1.0|       1.0|\n",
      "|                                انقلاب ضاق كان يعتبر علماء معتدل امثال شيخ حويني دور ماشي ومش حيخل  |     NEG|[0.47089331046230104,0.49520316091258115,0.03390352862511799]|  0.0|       1.0|\n",
      "|                                                     حري تعبير تتضم تحريض عنف فتنه طايفيه خطاب كراه |     NEG|  [0.470525832892676,0.5286899244425008,7.842426648230952E-4]|  0.0|       1.0|\n",
      "|                                         انصار مرس يحرق محكم متحف ملو منيا اعمال سلب نهب واسع مدينه |     NEG|  [0.4663738484970757,0.4779096787894383,0.05571647271348602]|  0.0|       1.0|\n",
      "|                                                         رحم شيخ فهد احمد تشم وعد قدام شيخ فهد احمد |     NEG|  [0.4584015447339616,0.5329233747909381,0.00867508047510021]|  0.0|       1.0|\n",
      "|                                 ساط رنس يقود طلب لحل ازم احتجاز يعود للبن بعد يمنع تروس حكومه تنجح | NEUTRAL|[0.4530007094479067,0.5468867515229016,1.1253902919182669E-4]|  1.0|       1.0|\n",
      "|خلال ايام اخيره نفذ قياده جنوبيه عسكريه نشاطا استكمال لكشف احباط نفق ارهاب تم تحييد داخل اراض اسر...|     POS|[0.4520503288152563,0.5466888931255779,0.0012607780591657493]|  2.0|       1.0|\n",
      "|                                                                                  تشهد حكم مدني عهد |     NEG|  [0.4425049709781501,0.4812464032252776,0.07624862579657225]|  0.0|       1.0|\n",
      "+----------------------------------------------------------------------------------------------------+--------+-------------------------------------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NaiveBayes Count Vector Features\n",
    "nb = NaiveBayes(smoothing=1 , modelType=\"multinomial\")\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)# model will make predictions and score on the test set\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"text\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.66882364915199\n"
     ]
    }
   ],
   "source": [
    "# Show the accuracy \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         728|\n",
      "|  1.0|         412|\n",
      "|  2.0|         454|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              780|\n",
      "|       1.0|              369|\n",
      "|       2.0|              445|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 67.127%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+-----+----------+\n",
      "|                text|Category|         probability|label|prediction|\n",
      "+--------------------+--------+--------------------+-----+----------+\n",
      "|انتم تريد يريد ال...| NEUTRAL|[0.47733571915763...|  1.0|       1.0|\n",
      "|اسوان اذا قار نسب...| NEUTRAL|[0.43957728520581...|  1.0|       1.0|\n",
      "|ندخل بء حرب اي دو...|     POS|[0.40077223999924...|  2.0|       1.0|\n",
      "|قوه قوه بار الله ...|     POS|[0.36955896506318...|  2.0|       1.0|\n",
      "|موشرا لد لء ضرب ع...| NEUTRAL|[0.34831800634019...|  1.0|       1.0|\n",
      "|غداد تعين ركن زيد...| NEUTRAL|[0.34246581373144...|  1.0|       1.0|\n",
      "|جماع اخو ارهاب قي...|     NEG|[0.33187391553347...|  0.0|       1.0|\n",
      "|مستقبل تكن زياره ...|     NEG|[0.30086814253564...|  0.0|       1.0|\n",
      "|منحو حجر وجد طايف...| NEUTRAL|[0.26702466936300...|  1.0|       1.0|\n",
      "|كلام ركي منسوب ال...| NEUTRAL|[0.26258795015241...|  1.0|       1.0|\n",
      "+--------------------+--------+--------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NaiveBayes using TF-IDF Features\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "#hashingTF\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "#idf\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=2) #minDocFreq: remove sparse terms\n",
    "#pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, hashingTF, idf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "#Partition Training & Test sets\n",
    "#80% train ,20% test\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"text\",\"Category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.6424062852209331\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         728|\n",
      "|  1.0|         412|\n",
      "|  2.0|         454|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              742|\n",
      "|       1.0|              419|\n",
      "|       2.0|              433|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 64.241%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Validation\n",
    "pipeline = Pipeline(stages=[regexTokenizer,countVectors, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(tweets)\n",
    "dataset = pipelineFit.transform(tweets)\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(nb.smoothing,[0.6, 0.8, 1.0])\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=nb, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "predictions = cvModel.transform(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.6691115761107667\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print (\"Model Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the label from our dataset\n",
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|         728|\n",
      "|  1.0|         412|\n",
      "|  2.0|         454|\n",
      "+-----+------------+\n",
      "\n",
      "the label from test\n",
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|              735|\n",
      "|       1.0|              407|\n",
      "|       2.0|              452|\n",
      "+----------+-----------------+\n",
      "\n",
      "Model accuracy: 66.939%\n"
     ]
    }
   ],
   "source": [
    "pl = predictions.select(\"label\", \"prediction\")\n",
    "\n",
    "print(\"the label from our dataset\") \n",
    "pl.groupby('label').agg({'label': 'count'}).show()\n",
    "\n",
    "print(\"the label from test\") \n",
    "pl.groupby('prediction').agg({'prediction': 'count'}).show()\n",
    "\n",
    "pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "acc = pl.filter(pl.label == pl.prediction).count() / pl.count()\n",
    "print(\"Model accuracy: %.3f%%\" % (acc * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
